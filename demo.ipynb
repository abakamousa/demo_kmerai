{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMncN74jRqPFfkznu+o1Kzu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abakamousa/demo_kmerai/blob/main/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# **MOBILE MONEY FRAUD DETECTION**\n",
        "\n",
        "*  **What is mobile money?** Mobile money is a digital payment platform in its own right. The mobile money account acts as an electronic wallet associated with the SIM card on a user’s cellphone. The user can send and receive funds or pay for services from their cellphone without the need for a traditional bank account. They can also use registered agents to deposit cash (cash-in) or transfer funds to other accounts and receive cash in exchange (cash-out).\n",
        "\n",
        "*   With over **$2 billion** of funds transferred every day, it’s easy to see why financial service companies such as Stripe are investing in mobile money markets. They recognize the potential growth in regions such as **sub-Saharan** Africa where access to formal banking systems may be limited. Offering fast transactions, convenient access and secure payments, mobile money gives users instant control of their finances.\n",
        "\n",
        "*  As this industry grows, it faces greater risks relating to mobile money fraud. In 2020, nearly $4 billion was lost to fraudulent mobile money activity and scams, a figure that’s expected to grow over time as fraudsters adopt increasingly sophisticated methods.\n",
        "\n",
        "*   The most common types of mobile money fraud involve **gaining control over a user’s cellphone** by **phishing** via voice calls (vishing) or SMS messages (smishing). Once scammers have access to the device, they may carry out SIM-swap fraud by instructing the phone service provider to transfer the number to one of their own SIM cards. Read more.).\n",
        "\n"
      ],
      "metadata": {
        "id": "sYnQL1JHxrx_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Install librairies**"
      ],
      "metadata": {
        "id": "piAr3fD8iGRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets\n",
        "#!pip install dython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPikpB0hiGxh",
        "outputId": "30d9c549-2be3-4366-801b-07bff26caef8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.64.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (6.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2022.9.24)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import librairies"
      ],
      "metadata": {
        "id": "fAAOM0owgVc4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z1MPu1oXf47o"
      },
      "outputs": [],
      "source": [
        "import numpy             as np \n",
        "import pandas            as pd \n",
        "import opendatasets      as od\n",
        "import seaborn           as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.preprocessing     import LabelEncoder\n",
        "from sklearn.ensemble          import RandomForestClassifier\n",
        "from sklearn.linear_model      import SGDClassifier\n",
        "from sklearn.linear_model      import LogisticRegression\n",
        "from xgboost                   import XGBClassifier\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.preprocessing     import RobustScaler\n",
        "from imblearn.over_sampling    import SMOTE \n",
        "from sklearn.model_selection   import train_test_split, GridSearchCV\n",
        "from collections               import Counter\n",
        "from sklearn.pipeline          import Pipeline\n",
        "#from dython.nominal        import associations #for correlation analysis between categorical and continuous values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset from kaggle"
      ],
      "metadata": {
        "id": "C35o4U7Tgctv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url=\"https://www.kaggle.com/datasets/ealaxi/paysim1\"\n",
        "od.download(url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvuGZJDPgVIB",
        "outputId": "1e56239f-c5be-4d4a-9f24-09c7987e4c16"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: abakamousa\n",
            "Your Kaggle Key: ··········\n",
            "Downloading paysim1.zip to ./paysim1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 178M/178M [00:01<00:00, 119MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "i-tKcgt8g50H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_df (df):\n",
        "    colName = []\n",
        "    for i in df.columns:\n",
        "        if (df[i].dtypes == 'object'):\n",
        "            colName.append(i)\n",
        "    # Encode Categorical Columns\n",
        "    le = LabelEncoder()\n",
        "    df[colName] = df[colName].apply(le.fit_transform)\n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "q-ZDTY4QgT-0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory data analysis"
      ],
      "metadata": {
        "id": "tsEj8UeSg_Ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/paysim1/PS_20174392719_1491204439457_log.csv\")"
      ],
      "metadata": {
        "id": "grWPUlcBg9_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "7cYD1oBrpePq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  step - maps a unit of time in the real world. In this case 1 step is 1 hour of time. Total steps 744 (30 days simulation).\n",
        "\n",
        "*    type - CASH-IN, CASH-OUT, DEBIT, PAYMENT and TRANSFER.\n",
        "\n",
        "*    amount - amount of the transaction in local currency.\n",
        "\n",
        "*    nameOrig - customer who started the transaction\n",
        "\n",
        "*    oldbalanceOrg - initial balance before the transaction\n",
        "\n",
        "*    newbalanceOrig - new balance after the transaction\n",
        "\n",
        "*    nameDest - customer who is the recipient of the transaction\n",
        "\n",
        "*    oldbalanceDest - initial balance recipient before the transaction. Note that there is not information for customers that start with M (Merchants).\n",
        "\n",
        "*    newbalanceDest - new balance recipient after the transaction. Note that there is not information for customers that start with M (Merchants).\n",
        "\n",
        "*    isFraud - This is the transactions made by the fraudulent agents inside the simulation. In this specific dataset the fraudulent behavior of the agents aims to profit by taking control of customers accounts and try to empty the funds by transferring to another account and then cashing out of the system.\n",
        "\n",
        "*    isFlaggedFraud - The business model aims to control massive transfers from one account to another and flags illegal attempts. An illegal attempt in this dataset is an attempt to transfer more than 200.000 in a single transaction.\n"
      ],
      "metadata": {
        "id": "iTIvY17vrGi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "ur2jOPnTpyLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "wGyEHyt2qS3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['isFraud'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "TdRAr6DDucny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['isFlaggedFraud'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "eQm0aXbmvV9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Countplot of each type of transactions**"
      ],
      "metadata": {
        "id": "75l3JjOEvwwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "ax=sns.countplot(x = \"type\", hue=\"isFraud\", data = df)\n",
        "plt.title('Countplot of different types of transaction (nonFraud and Fraud)')\n",
        "for p in ax.patches:\n",
        "  ax.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+50))\n",
        "        "
      ],
      "metadata": {
        "id": "3E8QAZEBqTdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remarque:** pas de transaction frauduleuse pour les transactions de type PAYMENT, CASH_IN et DEBIT"
      ],
      "metadata": {
        "id": "mK6yQUEF5yb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Proportion of different transactions**"
      ],
      "metadata": {
        "id": "i0PPKAKiwiS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type = df['type'].value_counts()\n",
        "transaction = type.index\n",
        "count = type.values\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.pie(count, labels=transaction, autopct='%1.0f%%')\n",
        "plt.legend(loc='lower left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AK-AsTPJqT7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset splitting**\n",
        "\n",
        "Etant donné que l'on peut rencontrer des fraudes sur des opérations de PAYMENT, CASH_IN et DEBIT, nous allons procéder à un découpage de notre jeu de données en deux:\n",
        "\n",
        "*   Un premier jeu destiné à la réalisation de l'apprentissage non supervisé pour détecter les anomalies en prenant en compte les transactions de type PAYMENT, CASH_IN et DEBIT.\n",
        "*   Un second jeu destiné à être utilisé pour réaliser un apprentissage supervisé à en prenant en compte les transactions de CASH_OUT et TRANSFER\n",
        "\n"
      ],
      "metadata": {
        "id": "pQhX7f4efDX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_unsupervised = df.loc[(df[\"type\"] == \"PAYMENT\") | (df[\"type\"] == \"CASH_IN\") | (df[\"type\"] == \"DEBIT\")]\n",
        "df_supervised   = df.loc[(df[\"type\"] == \"TRANSFER\") | (df[\"type\"] == \"CASH_OUT\")]"
      ],
      "metadata": {
        "id": "3gkZnSKqfALV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data preparation for supervised ML with df_supervised**"
      ],
      "metadata": {
        "id": "QSf4wPAvtzO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of duplicated rows: \", df_supervised.duplicated().sum())"
      ],
      "metadata": {
        "id": "NFP5SBWXuq6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#label encoding\n",
        "df_supervised = encode_df(df_supervised)"
      ],
      "metadata": {
        "id": "EY0eDGrDtxNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correlation analysis**"
      ],
      "metadata": {
        "id": "kaxXtnlNfVft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(df_supervised.corr(), annot = True, fmt='.1g')"
      ],
      "metadata": {
        "id": "cOkShW6boN6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remarque:** La valeur max de corrélation entre deux variables distinctes de notre dataset est de 0.8.  "
      ],
      "metadata": {
        "id": "XAIBWzho3do3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Boxplot**"
      ],
      "metadata": {
        "id": "Bf1gR88eCycf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "sns.boxplot(data=df_supervised, orient=\"h\", palette=\"Set2\")"
      ],
      "metadata": {
        "id": "TclYpAH1CxkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class analysis"
      ],
      "metadata": {
        "id": "r87ogBhQe9XS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_supervised['isFraud'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "inaCJ_Cce40a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remarque: \n",
        "* l'on note que les features ne sont pas à la même échelle\n",
        "* l'on note la présence d'outlier --> L'on tiendra compte de cela dans le choix de la méthode de normalisation des données"
      ],
      "metadata": {
        "id": "lC8xr2K9DVCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature scaling**"
      ],
      "metadata": {
        "id": "_ip-uyHf0j87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = RobustScaler()\n",
        "#df_supervised_scaled = scaler.fit_transform(df_supervised)"
      ],
      "metadata": {
        "id": "Amz3Ik2E0i7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Test split**"
      ],
      "metadata": {
        "id": "mpK1RSdX6vCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#feature = df_supervised_scaled[:,:-2]\n",
        "#target  = df_supervised_scaled[:,-2]\n",
        "feature = df_supervised.drop(['isFraud', 'isFlaggedFraud'], axis=1)\n",
        "target  = df_supervised.isFraud\n"
      ],
      "metadata": {
        "id": "sl9faX2u632b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature selection\n",
        "new_feature = SelectKBest(f_classif, k=7).fit_transform(feature, target)"
      ],
      "metadata": {
        "id": "n8PUbBr8jqAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(new_feature, target, test_size=0.2)"
      ],
      "metadata": {
        "id": "_oTViUgtjsW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resampling**"
      ],
      "metadata": {
        "id": "mXkwQVXShMdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(sampling_strategy='minority', random_state=237)\n",
        "\n",
        "X_res, y_res = sm.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "6ArZOsY_hl6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Resampled dataset shape %s' % Counter(y_res))"
      ],
      "metadata": {
        "id": "PEnAKcUNkenX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "NgBXuSbEhMr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#models\n",
        "clf1 = SGDClassifier()\n",
        "clf2 = RandomForestClassifier()\n",
        "clf3 = LogisticRegression()\n",
        "clf4 = XGBClassifier()\n"
      ],
      "metadata": {
        "id": "2L_vd1bRg-KV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pipeline\n",
        "\n",
        "pipe_SGD  = Pipeline([('scaler', scaler), ('SGD', clf1)])\n",
        "pipe_RF   = Pipeline(steps=[(\"scaler\", scaler), (\"RF\", clf2)]) \n",
        "pipe_LR   = Pipeline(steps=[(\"scaler\", scaler), (\"LogisticRegression\", clf3)])\n",
        "pipe_XGB  = Pipeline(steps=[(\"scaler\", scaler), (\"XGB\", clf4)])"
      ],
      "metadata": {
        "id": "13ltfDAlcejB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#grid parameters\n",
        "\n",
        "\n",
        "hyper_params_SGD = [{\n",
        "'SGD__loss' : ['hinge', 'log', 'squared_hinge', 'modified_huber'],\n",
        "'SGD__alpha' : np.arange(0, 0.1, 0.01),\n",
        "'SGD__penalty' : ['l2', 'l1']\n",
        "}]\n",
        "\n",
        "hyper_params_RF = [{ \n",
        "'RF__n_estimators' : [100, 200, 500, 1000],\n",
        "'RF__max_features' : [\"auto\", \"sqrt\", \"log2\"],\n",
        "'RF__bootstrap': [True],\n",
        "'RF__criterion': ['gini', 'entropy'],\n",
        "'RF__oob_score': [True, False]\n",
        "}]\n",
        "\n",
        "\n",
        "hyper_params_LR = [{\n",
        "'LogisticRegression__solver': ['newton-cg', 'sag', 'lbfgs'],\n",
        "'LogisticRegression__multi_class': ['ovr', 'multinomial']\n",
        "}]\n",
        "\n",
        "hyper_params_XGB =  [{\n",
        "'XGB__nthread':[4], #when use hyperthread, xgboost may become slower\n",
        "'XGB__objective':['binary:logistic'],\n",
        "'XGB__learning_rate': [0.05], #so called `eta` value\n",
        "'XGB__max_depth': [6],\n",
        "'XGB__min_child_weight': [11],\n",
        "'XGB__silent': [1],\n",
        "'XGB__subsample': [0.8],\n",
        "'XGB__colsample_bytree': [0.7],\n",
        "'XGB__n_estimators': [5], #number of trees, change it to 1000 for better results\n",
        "'XGB__missing':[-999],\n",
        "'XGB__seed': [1337]}]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ud47TmMCXCdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SGD_grid_search = GridSearchCV(estimator=pipe_SGD,\n",
        "        param_grid=hyper_params_SGD,\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1,\n",
        "        cv=3,\n",
        "        verbose = 10)\n",
        "\n",
        "RF_grid_search = GridSearchCV(estimator=pipe_RF,\n",
        "        param_grid=hyper_params_RF,\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1,\n",
        "        cv=3,\n",
        "        verbose = 10)\n",
        "\n",
        "LR_grid_search = GridSearchCV(estimator=pipe_LR,\n",
        "        param_grid=hyper_params_LR,\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1,\n",
        "        cv=3,\n",
        "        verbose = 10)\n",
        "\n",
        "XGB_grid_search = GridSearchCV(estimator=pipe_XGB,\n",
        "        param_grid=hyper_params_XGB,\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1,\n",
        "        cv=3,\n",
        "        verbose = 10)\n",
        "\n",
        "grids = [SGD_grid_search, RF_grid_search, XGB_grid_search, LR_grid_search]"
      ],
      "metadata": {
        "id": "eQDndNZd74Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for param in XGB_grid_search.get_params().keys():\n",
        "#    print(param)"
      ],
      "metadata": {
        "id": "WvlfmSyt75VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for pipe in grids:\n",
        "    pipe.fit(X_res, y_res)"
      ],
      "metadata": {
        "id": "4DPIBVlQ7dr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MdKvfTylW-dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance evaluation"
      ],
      "metadata": {
        "id": "uStltkKyhVeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p4djDG0hhUKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "cBvpM4qahaTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "79V6Sg-5hUbq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}